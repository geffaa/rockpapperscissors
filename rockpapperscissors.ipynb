{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "name = \"Yodhimas Geffananda\"\n",
        "email = \"yodhimasgeffananda@mail.ugm.ac.id\"\n",
        "print(f\"Name: {name}\\nEmail: {email}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXJKGBY4ivIE",
        "outputId": "cd44efd5-173c-4fcd-ca7b-47cd76427a16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Yodhimas Geffananda\n",
            "Email: yodhimasgeffananda@mail.ugm.ac.id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
        "!unzip -q rockpaperscissors.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHqE80fua8Ql",
        "outputId": "1ec694ed-081c-461c-9349-138e8f894502"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 08:59:09--  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240617%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240617T085909Z&X-Amz-Expires=300&X-Amz-Signature=8ee57c3ad02312bafb049cee4fdfa52567dc6929a2ec40fa8a96251d019d289d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-06-17 08:59:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240617%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240617T085909Z&X-Amz-Expires=300&X-Amz-Signature=8ee57c3ad02312bafb049cee4fdfa52567dc6929a2ec40fa8a96251d019d289d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/octet-stream]\n",
            "Saving to: ‘rockpaperscissors.zip’\n",
            "\n",
            "rockpaperscissors.z 100%[===================>] 307.92M   213MB/s    in 1.4s    \n",
            "\n",
            "2024-06-17 08:59:11 (213 MB/s) - ‘rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_jTYWixalZI",
        "outputId": "4cdb1fec-78b4-4709-c1d1-781604807efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image data generator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.4\n",
        ")\n",
        "\n",
        "# Training dataset\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    'rockpaperscissors/rps-cv-images',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Validation dataset\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    'rockpaperscissors/rps-cv-images',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.4\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'rockpaperscissors/rps-cv-images',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    'rockpaperscissors/rps-cv-images',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oJ0SzkMbGlB",
        "outputId": "e16c15cf-27e4-4167-937f-fbc70fb3efb4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F28GHRK5bKel",
        "outputId": "dd37c77a-c8e8-4724-84aa-4c7e01a31446"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36992)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               18940416  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19035203 (72.61 MB)\n",
            "Trainable params: 19035203 (72.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=15,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDPhOy9pbNk3",
        "outputId": "971a3be9-98be-4f68-c69f-40dc0c337768"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "41/41 - 108s - loss: 1.0670 - accuracy: 0.5312 - val_loss: 0.6586 - val_accuracy: 0.7442 - 108s/epoch - 3s/step\n",
            "Epoch 2/15\n",
            "41/41 - 106s - loss: 0.4875 - accuracy: 0.8105 - val_loss: 0.2618 - val_accuracy: 0.9167 - 106s/epoch - 3s/step\n",
            "Epoch 3/15\n",
            "41/41 - 112s - loss: 0.2998 - accuracy: 0.8931 - val_loss: 0.3090 - val_accuracy: 0.8958 - 112s/epoch - 3s/step\n",
            "Epoch 4/15\n",
            "41/41 - 114s - loss: 0.2219 - accuracy: 0.9165 - val_loss: 0.1329 - val_accuracy: 0.9583 - 114s/epoch - 3s/step\n",
            "Epoch 5/15\n",
            "41/41 - 109s - loss: 0.1553 - accuracy: 0.9516 - val_loss: 0.1371 - val_accuracy: 0.9444 - 109s/epoch - 3s/step\n",
            "Epoch 6/15\n",
            "41/41 - 112s - loss: 0.1399 - accuracy: 0.9555 - val_loss: 0.1387 - val_accuracy: 0.9549 - 112s/epoch - 3s/step\n",
            "Epoch 7/15\n",
            "41/41 - 111s - loss: 0.1524 - accuracy: 0.9470 - val_loss: 0.0897 - val_accuracy: 0.9688 - 111s/epoch - 3s/step\n",
            "Epoch 8/15\n",
            "41/41 - 113s - loss: 0.0973 - accuracy: 0.9743 - val_loss: 0.0835 - val_accuracy: 0.9664 - 113s/epoch - 3s/step\n",
            "Epoch 9/15\n",
            "41/41 - 113s - loss: 0.0702 - accuracy: 0.9782 - val_loss: 0.1369 - val_accuracy: 0.9491 - 113s/epoch - 3s/step\n",
            "Epoch 10/15\n",
            "41/41 - 113s - loss: 0.0571 - accuracy: 0.9813 - val_loss: 0.0924 - val_accuracy: 0.9711 - 113s/epoch - 3s/step\n",
            "Epoch 11/15\n",
            "41/41 - 112s - loss: 0.0724 - accuracy: 0.9750 - val_loss: 0.0774 - val_accuracy: 0.9745 - 112s/epoch - 3s/step\n",
            "Epoch 12/15\n",
            "41/41 - 114s - loss: 0.0416 - accuracy: 0.9852 - val_loss: 0.0694 - val_accuracy: 0.9769 - 114s/epoch - 3s/step\n",
            "Epoch 13/15\n",
            "41/41 - 118s - loss: 0.0963 - accuracy: 0.9688 - val_loss: 0.0757 - val_accuracy: 0.9734 - 118s/epoch - 3s/step\n",
            "Epoch 14/15\n",
            "41/41 - 110s - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.1465 - val_accuracy: 0.9641 - 110s/epoch - 3s/step\n",
            "Epoch 15/15\n",
            "41/41 - 112s - loss: 0.0672 - accuracy: 0.9789 - val_loss: 0.0809 - val_accuracy: 0.9769 - 112s/epoch - 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(validation_generator, verbose=2)\n",
        "print(f\"Accuracy: {scores[1]*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKJZqdTiWOe",
        "outputId": "790f8805-e1f6-4ba0-846f-4d538063f809"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 - 16s - loss: 0.0801 - accuracy: 0.9771 - 16s/epoch - 585ms/step\n",
            "Accuracy: 97.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "    img_tensor /= 255.\n",
        "\n",
        "    prediction = model.predict(img_tensor)\n",
        "    classes = np.argmax(prediction, axis=1)\n",
        "\n",
        "    labels = list(train_generator.class_indices.keys())\n",
        "    return labels[classes[0]]\n",
        "\n",
        "# Contoh prediksi\n",
        "img_path = 'rockpaperscissors/rps-cv-images/rock/gjdBDXv7avQwgTr3.png'\n",
        "prediction = predict_image(img_path)\n",
        "print(f'Prediction: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIl3cvY6iaDa",
        "outputId": "cdb49773-84b9-4b38-c6ea-6e41c2bf97b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step\n",
            "Prediction: rock\n"
          ]
        }
      ]
    }
  ]
}